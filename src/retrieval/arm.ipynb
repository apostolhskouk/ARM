{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2246bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 'Aram':\n",
      "[' ,', ' ]', ' khachaturian', ' khatchaturian', ' manukian', '_', '_khachaturian', '_khatchaturian', '_manukian', 'aic', 'aic_language', 'aic_script', 'ais', 'aized', 'ay', 'azd', 'bagh', 'barri', 'e', 'ean', 'eans', 'eans_in_israel', 'id', 'is', 'is_knight', 'is_rami', 'yan']\n"
     ]
    }
   ],
   "source": [
    "from src.utils.trie_index import find_next_word_continuations, get_distinct_tokens_from_trie\n",
    "trie_index_path = \"/data/hdd1/users/akouk/ARM/ARM/assets/feverous/trie_indexes/ngrams_table_level_1_3.marisa\"\n",
    "results = find_next_word_continuations(\"Aram\", trie_index_path)\n",
    "print(\"Results for 'Aram':\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d5c0028",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/akouk/miniconda3/envs/tolis/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/akouk/miniconda3/envs/tolis/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/akouk/miniconda3/envs/tolis/lib/python3.11/site-packages/guidance/metrics/_metrics.py\", line 199, in _monitor_fn\n",
      "    gpu_stats = gpustat.GPUStatCollection.new_query()\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/akouk/miniconda3/envs/tolis/lib/python3.11/site-packages/gpustat/core.py\", line 624, in new_query\n",
      "    N.nvmlShutdown()\n",
      "  File \"/home/akouk/miniconda3/envs/tolis/lib/python3.11/site-packages/pynvml.py\", line 2262, in nvmlShutdown\n",
      "    ret = fn()\n",
      "          ^^^^\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from guidance import models\n",
    "import torch\n",
    "\n",
    "MODEL_NAME = \"/data/hdd1/users/akouk/ARM/ARM/assets/cache/Qwen2.5-32B-Instruct-Q4_K_M.gguf\"\n",
    "model = models.LlamaCpp(\n",
    "    MODEL_NAME,\n",
    "    n_gpu_layers=-1,\n",
    "    n_ctx=32768,\n",
    "    echo=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e1c3a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_list_size(string_list, n):\n",
    "    if not string_list:\n",
    "        return []\n",
    "    if len(string_list) <= n:\n",
    "        return string_list\n",
    "    max_s_len = 0\n",
    "    for s_item in string_list:\n",
    "        if len(s_item) > max_s_len:\n",
    "            max_s_len = len(s_item)\n",
    "    optimal_trunc_len = 0\n",
    "    low = 0\n",
    "    high = max_s_len\n",
    "\n",
    "    while low <= high:\n",
    "        mid_len = low + (high - low) // 2\n",
    "        \n",
    "        truncated_set = {s_val[:mid_len] for s_val in string_list}\n",
    "        \n",
    "        if len(truncated_set) <= n:\n",
    "            optimal_trunc_len = mid_len\n",
    "            low = mid_len + 1 \n",
    "        else:\n",
    "            high = mid_len - 1\n",
    "            \n",
    "    final_truncated_set = {s_val[:optimal_trunc_len] for s_val in string_list}\n",
    "    return list(final_truncated_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c274e383",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-17 10:26:34,202 - INFO - Use pytorch device_name: cuda:0\n",
      "2025-05-17 10:26:34,203 - INFO - Load pretrained SentenceTransformer: BAAI/bge-m3\n"
     ]
    }
   ],
   "source": [
    "from src.utils.trie_index import find_next_word_continuations\n",
    "from src.retrieval.base import RetrievalResult\n",
    "from src.retrieval.bm25 import PyseriniBM25Retriever\n",
    "from typing import List\n",
    "import guidance\n",
    "from guidance import gen, select\n",
    "from typing import List\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "from pulp import LpProblem, LpVariable, lpSum, LpMaximize, LpBinary\n",
    "from pulp.apis import PULP_CBC_CMD\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import faiss\n",
    "\n",
    "# Define these constants if FaissDenseRetriever class is not imported here\n",
    "# Otherwise, you can use FaissDenseRetriever.INDEX_FILENAME, etc.\n",
    "YOUR_FAISS_INDEX_DIR = \"/data/hdd1/users/akouk/ARM/ARM/assets/feverous/faiss_indexes/dense_row_UAE-Large-V1\" # Path to your FAISS index\n",
    "FAISS_INDEX_FILENAME = \"index.faiss\"\n",
    "FAISS_METADATA_FILENAME = \"metadata.pkl\"\n",
    "\n",
    "# Global variables to store pre-loaded FAISS data\n",
    "loaded_faiss_index = None\n",
    "loaded_faiss_text_to_original_idx_map = None \n",
    "# Path to your FAISS index directory\n",
    "\n",
    "def initialize_faiss_retrieval_assets_by_text(faiss_folder_path: str = YOUR_FAISS_INDEX_DIR):\n",
    "    \"\"\"\n",
    "    Loads FAISS index and metadata, creating a map from FAISS '_text' content to FAISS internal index.\n",
    "    This should ideally be called once when the application starts.\n",
    "    \"\"\"\n",
    "    global loaded_faiss_index, loaded_faiss_text_to_original_idx_map\n",
    "\n",
    "    # Prevent re-initialization if already done\n",
    "    if loaded_faiss_index is not None and loaded_faiss_text_to_original_idx_map is not None:\n",
    "        # print(\"FAISS assets (by text) already initialized.\")\n",
    "        return True\n",
    "\n",
    "    index_file = os.path.join(faiss_folder_path, FAISS_INDEX_FILENAME)\n",
    "    metadata_file = os.path.join(faiss_folder_path, FAISS_METADATA_FILENAME)\n",
    "\n",
    "    if not os.path.exists(index_file) or not os.path.exists(metadata_file):\n",
    "        print(f\"Error: FAISS index or metadata not found in '{faiss_folder_path}'. Pre-computed embeddings unavailable.\")\n",
    "        loaded_faiss_index = None \n",
    "        loaded_faiss_text_to_original_idx_map = {}\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        print(f\"Initializing FAISS assets (by text) from: {faiss_folder_path}\")\n",
    "        loaded_faiss_index = faiss.read_index(index_file)\n",
    "        \n",
    "        with open(metadata_file, 'rb') as f:\n",
    "            faiss_metadata_list = pickle.load(f)\n",
    "        \n",
    "        temp_text_map = {}\n",
    "        texts_processed = 0\n",
    "        for original_idx, meta_item in enumerate(faiss_metadata_list):\n",
    "            text_content = meta_item.get('_text') \n",
    "            if text_content is not None:\n",
    "                texts_processed += 1\n",
    "                # If duplicate texts exist in FAISS metadata, this takes the first encountered FAISS index.\n",
    "                # This should be fine if the text content itself is unique enough for your rows/sentences.\n",
    "                if text_content not in temp_text_map:\n",
    "                    temp_text_map[text_content] = original_idx\n",
    "        \n",
    "        loaded_faiss_text_to_original_idx_map = temp_text_map\n",
    "        print(f\"FAISS assets (by text) initialized. Index has {loaded_faiss_index.ntotal} vectors.\")\n",
    "        print(f\"FAISS text-to-index map created with {len(loaded_faiss_text_to_original_idx_map)} unique text entries from {texts_processed} texts in metadata.pkl.\")\n",
    "        if not loaded_faiss_text_to_original_idx_map and texts_processed > 0:\n",
    "            print(\"Warning: FAISS text-to-index map is empty, but texts were found in metadata.pkl. This is unexpected.\")\n",
    "        elif not loaded_faiss_text_to_original_idx_map:\n",
    "            print(\"Warning: FAISS text-to-index map is empty. No '_text' fields found or all were None in metadata.pkl.\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Critical error loading FAISS assets (by text): {e}\")\n",
    "        loaded_faiss_index = None\n",
    "        loaded_faiss_text_to_original_idx_map = {}\n",
    "        return False\n",
    "        \n",
    "        \n",
    "trie_index_path = \"/data/hdd1/users/akouk/ARM/ARM/assets/feverous/trie_indexes/ngrams_table_level_1_3.marisa\"\n",
    "index = PyseriniBM25Retriever()\n",
    "bm25_index_global = PyseriniBM25Retriever()\n",
    "bm25_output_folder_global = \"/data/hdd1/users/akouk/ARM/ARM/assets/feverous/pyserini_indexes/bm25_row_index\" # Your path\n",
    "embedding_model_global = SentenceTransformer('BAAI/bge-m3')\n",
    "trie_index_path_global = \"/data/hdd1/users/akouk/ARM/ARM/assets/feverous/trie_indexes/ngrams_table_level_1_3.marisa\"\n",
    "\n",
    "COMPATIBILITY_SEMANTIC_WEIGHT = 0.5\n",
    "COMPATIBILITY_EXACT_WEIGHT = 0.5\n",
    "MAX_KEYWORD_LENGTH = 20 \n",
    "MAX_REPHRASES = 5      \n",
    "BM25_K = 5\n",
    "RERANK_TOP_K = 5\n",
    "SCORE_WEIGHT_BM25 = 0.4\n",
    "SCORE_WEIGHT_EMBEDDING = 0.6\n",
    "K_MIP_SELECT = 5\n",
    "\n",
    "def parse_table_object_string(table_str: str) -> dict[str, any]:\n",
    "    parts = table_str.split(\" [SEP] \", 1)\n",
    "    table_name = parts[0]\n",
    "    columns_data = {}\n",
    "    if len(parts) > 1 and parts[1]:\n",
    "        content_part = parts[1].strip()\n",
    "        \n",
    "        if content_part.startswith(\"[H] \"):\n",
    "            current_attributes_str = content_part[4:]\n",
    "        else:\n",
    "            current_attributes_str = content_part\n",
    "        \n",
    "        attributes = current_attributes_str.split(\" , [H] \")\n",
    "        \n",
    "        for attr_str in attributes:\n",
    "            header_content_split = attr_str.split(\":\", 1)\n",
    "            if len(header_content_split) == 2:\n",
    "                header, content = header_content_split[0].strip(), header_content_split[1].strip()\n",
    "                if header not in columns_data:\n",
    "                    columns_data[header] = []\n",
    "                columns_data[header].append(content)\n",
    "    return {\"name\": table_name, \"columns\": columns_data}\n",
    "\n",
    "def get_tokens(text: str) -> set[str]:\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) # Remove punctuation\n",
    "    return set(text.split())\n",
    "\n",
    "def jaccard_similarity(set1: set[str], set2: set[str]) -> float:\n",
    "    if not set1 and not set2: return 1.0\n",
    "    if not set1 or not set2: return 0.0\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    return intersection / union if union > 0 else 0.0\n",
    "\n",
    "def overlap_coefficient(set1: set[str], set2: set[str]) -> float:\n",
    "    if not set1 and not set2: return 1.0\n",
    "    if not set1 or not set2: return 0.0\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    min_len = min(len(set1), len(set2))\n",
    "    return intersection / min_len if min_len > 0 else 0.0\n",
    "\n",
    "def get_semantic_similarity(text1: str, text2: str, model) -> float:\n",
    "    # Assumes model is a SentenceTransformer model\n",
    "    emb1 = model.encode(text1, convert_to_tensor=True, show_progress_bar=False)\n",
    "    emb2 = model.encode(text2, convert_to_tensor=True, show_progress_bar=False)\n",
    "    return util.cos_sim(emb1, emb2).item()\n",
    "\n",
    "# --- Compatibility Calculation Functions ---\n",
    "\n",
    "def calculate_table_table_compatibility(table1_parsed: dict[str, any], table2_parsed: dict[str, any], model) -> float:\n",
    "    max_col_pair_compatibility = 0.0\n",
    "    table1_headers = list(table1_parsed[\"columns\"].keys())\n",
    "    table2_headers = list(table2_parsed[\"columns\"].keys())\n",
    "\n",
    "    for h1 in table1_headers:\n",
    "        for h2 in table2_headers:\n",
    "            header_sem_sim = get_semantic_similarity(h1, h2, model)\n",
    "            \n",
    "            col1_value_tokens = set()\n",
    "            for v_val in table1_parsed[\"columns\"].get(h1, []): col1_value_tokens.update(get_tokens(v_val))\n",
    "            col2_value_tokens = set()\n",
    "            for v_val in table2_parsed[\"columns\"].get(h2, []): col2_value_tokens.update(get_tokens(v_val))\n",
    "            \n",
    "            exact_val_sim = jaccard_similarity(col1_value_tokens, col2_value_tokens)\n",
    "            \n",
    "            col_pair_comp = (COMPATIBILITY_SEMANTIC_WEIGHT * header_sem_sim +\n",
    "                             COMPATIBILITY_EXACT_WEIGHT * exact_val_sim)\n",
    "            if col_pair_comp > max_col_pair_compatibility:\n",
    "                max_col_pair_compatibility = col_pair_comp\n",
    "    return max_col_pair_compatibility\n",
    "\n",
    "def calculate_table_passage_compatibility(table_parsed: dict[str, any], passage_text: str, model) -> float:\n",
    "    max_cell_sentence_compatibility = 0.0\n",
    "    passage_tokens = get_tokens(passage_text)\n",
    "    \n",
    "    for header, cells in table_parsed[\"columns\"].items():\n",
    "        for cell_content in cells:\n",
    "            cell_sem_sim = get_semantic_similarity(cell_content, passage_text, model)\n",
    "            cell_tokens = get_tokens(cell_content)\n",
    "            exact_val_sim = overlap_coefficient(cell_tokens, passage_tokens)\n",
    "            \n",
    "            cell_sentence_comp = (COMPATIBILITY_SEMANTIC_WEIGHT * cell_sem_sim +\n",
    "                                  COMPATIBILITY_EXACT_WEIGHT * exact_val_sim)\n",
    "            if cell_sentence_comp > max_cell_sentence_compatibility:\n",
    "                max_cell_sentence_compatibility = cell_sentence_comp\n",
    "    return max_cell_sentence_compatibility\n",
    "\n",
    "def calculate_passage_passage_compatibility(passage1_text: str, passage2_text: str, model) -> float:\n",
    "    sem_sim = get_semantic_similarity(passage1_text, passage2_text, model)\n",
    "    passage1_tokens = get_tokens(passage1_text)\n",
    "    passage2_tokens = get_tokens(passage2_text)\n",
    "    exact_val_sim = overlap_coefficient(passage1_tokens, passage2_tokens)\n",
    "    return (COMPATIBILITY_SEMANTIC_WEIGHT * sem_sim +\n",
    "            COMPATIBILITY_EXACT_WEIGHT * exact_val_sim)\n",
    "\n",
    "# --- MIP Solver Function ---\n",
    "def solve_mip_object_selection(\n",
    "    candidate_objects: list[dict[str, any]], # This list now contains ALL M unique retrieved objects\n",
    "    k_select: int,\n",
    "    model # SentenceTransformer model\n",
    ") -> list[dict[str, any]]:\n",
    "    \n",
    "    num_objects = len(candidate_objects) # M\n",
    "    if num_objects == 0: return []\n",
    "    if k_select <= 0 : return [] \n",
    "    if k_select > num_objects: k_select = num_objects # Cannot select more than available\n",
    "\n",
    "    # C_ij calculation (remains the same)\n",
    "    C = np.zeros((num_objects, num_objects))\n",
    "    for i in range(num_objects):\n",
    "        for j in range(i + 1, num_objects): \n",
    "            obj_i = candidate_objects[i]\n",
    "            obj_j = candidate_objects[j]\n",
    "            comp_val = 0.0\n",
    "            if obj_i['source_type'] == 'table' and obj_j['source_type'] == 'table':\n",
    "                comp_val = calculate_table_table_compatibility(obj_i['parsed_content'], obj_j['parsed_content'], model)\n",
    "            elif obj_i['source_type'] == 'table' and obj_j['source_type'] == 'passage':\n",
    "                comp_val = calculate_table_passage_compatibility(obj_i['parsed_content'], obj_j['text'], model)\n",
    "            elif obj_i['source_type'] == 'passage' and obj_j['source_type'] == 'table':\n",
    "                comp_val = calculate_table_passage_compatibility(obj_j['parsed_content'], obj_i['text'], model)\n",
    "            elif obj_i['source_type'] == 'passage' and obj_j['source_type'] == 'passage':\n",
    "                comp_val = calculate_passage_passage_compatibility(obj_i['text'], obj_j['text'], model)\n",
    "            C[i, j] = C[j, i] = comp_val \n",
    "    \n",
    "    # R_i are pre-calculated and passed in candidate_objects[i]['relevance_score_R_i']\n",
    "    R = [obj['relevance_score_R_i'] for obj in candidate_objects]\n",
    "\n",
    "    prob = LpProblem(\"ObjectSelectionMIP\", LpMaximize)\n",
    "    b = [LpVariable(f\"b_{i}\", cat=LpBinary) for i in range(num_objects)]\n",
    "    c_vars = {} \n",
    "    for i in range(num_objects):\n",
    "        for j in range(i + 1, num_objects):\n",
    "            c_vars[(i,j)] = LpVariable(f\"c_{i}_{j}\", cat=LpBinary)\n",
    "\n",
    "    objective = lpSum(R[i] * b[i] for i in range(num_objects))\n",
    "    if c_vars: # Add compatibility term only if there are pairs to consider\n",
    "        objective += lpSum(C[i][j] * c_vars[(i,j)] for i in range(num_objects) for j in range(i+1, num_objects))\n",
    "    prob += objective\n",
    "\n",
    "    prob += lpSum(b[i] for i in range(num_objects)) == k_select \n",
    "    \n",
    "    if k_select > 1 and c_vars: \n",
    "         prob += lpSum(c_vars[(i,j)] for i in range(num_objects) for j in range(i+1, num_objects)) <= 2 * (k_select - 1)\n",
    "    elif k_select == 1 and c_vars: \n",
    "         prob += lpSum(c_vars[(i,j)] for i in range(num_objects) for j in range(i+1, num_objects)) == 0\n",
    "\n",
    "    if c_vars:\n",
    "        for i in range(num_objects):\n",
    "            for j in range(i + 1, num_objects):\n",
    "                prob += 2 * c_vars[(i,j)] <= b[i] + b[j]\n",
    "    \n",
    "    prob.solve(PULP_CBC_CMD(msg=0)) \n",
    "\n",
    "    selected_objects_indices = [i for i, var_b in enumerate(b) if var_b.value() is not None and var_b.value() > 0.5]\n",
    "    \n",
    "    return [candidate_objects[idx] for idx in selected_objects_indices]\n",
    "\n",
    "\n",
    "\n",
    "@guidance(stateless=False) # Needs to be stateful to use Python logic based on captures\n",
    "def dynamic_retrieval_guidance(lm, user_query: str):\n",
    "    if loaded_faiss_index is None or loaded_faiss_text_to_original_idx_map is None:\n",
    "        print(\"FAISS assets not pre-initialized, attempting to initialize now (by text)...\")\n",
    "        if not initialize_faiss_retrieval_assets_by_text(): # Uses YOUR_FAISS_INDEX_DIR\n",
    "            print(\"Failed to initialize FAISS assets. Pre-computed embeddings will not be used.\")\n",
    "            \n",
    "    # 1. Decompose query into keywords\n",
    "    lm += f\"\"\"You are given a user question, your task is to decompose the user question into contiguous, non-overlapping substrings that can\n",
    "cover different information mentioned in the user question. For each substring, generate n-grams that are the most relevant to\n",
    "the substring. Prefare lengthy n-grams over short ones. Based on the generated relevant n-grams, generate a list of relevant objects, including their names, content, and\n",
    "connections between these objects. From these candidate objects, you should identify the minimum number of objects that can\n",
    "be used to answer the user question based on the relevance between the object name, object content and user question as well as\n",
    "the relevance of the object connections. You should end your response with <>.\n",
    "\n",
    "User question: What is the birth date of the director of the movie 'Inception' which was released in 2010?\n",
    "The relevant keywords are birth date | director | movie 'Inception' | released in 2010\n",
    "The relevant n-grams are birth date (born, date of birth, DOB) | director (directed by, filmmaker, film director) | movie 'Inception' (Inception, film Inception, movie named Inception) | released in 2010 (2010, release year 2010, came out 2010)\n",
    "\n",
    "Here are the objects that can be relevant:\n",
    "(...4 objects omitted...)\n",
    "- Inception was directed by Christopher Nolan.\n",
    "- Lions live in the jungle.\n",
    "\n",
    "\n",
    "Here are the objects that are enough to answer the user query:\n",
    "(...2 objects omitted...)\n",
    "- Inception was directed by Christopher Nolan.\n",
    "\n",
    "\n",
    "User question: {user_query}\n",
    "The relevant keywords are: \"\"\"\n",
    "    lm += gen(name='keywords_str', stop='\\n')\n",
    "    keywords_str = lm['keywords_str'].strip()\n",
    "    keywords = [k.strip() for k in keywords_str.split('|') if k.strip()]\n",
    "\n",
    "    # 2. Rephrase keywords using dynamic constraints (LLM part with Python logic)\n",
    "    lm += \"\\nThe relevant n-grams are\"\n",
    "    all_parsed_ngrams_for_bm25_queries = []\n",
    "    # ... (N-gram generation loop remains IDENTICAL to your last provided version) ...\n",
    "    for keyword_idx, keyword in enumerate(keywords):\n",
    "        if keyword_idx > 0: lm += \" |\"\n",
    "        lm += f\" {keyword} (\"\n",
    "        ngrams_for_this_keyword_list = []\n",
    "        current_ngram_being_built_in_python = \"\"\n",
    "        keyword_ngram_generation_finished = False\n",
    "        for rephrase_num in range(MAX_REPHRASES): # MAX_REPHRASES needs to be defined\n",
    "            first_token_var = f\"rephrase_{keyword_idx}_{rephrase_num}_first_token\"\n",
    "            lm += gen(name=first_token_var, max_tokens=1)\n",
    "            if lm[first_token_var] == ')':\n",
    "                keyword_ngram_generation_finished = True; break\n",
    "            current_ngram_being_built_in_python = lm[first_token_var]\n",
    "            if len(current_ngram_being_built_in_python) < 2 and lm[first_token_var] != ' ':\n",
    "                second_token_var = f\"rephrase_{keyword_idx}_{rephrase_num}_second_token\"\n",
    "                lm += gen(name=second_token_var, max_tokens=1)\n",
    "                if lm[second_token_var] == ')':\n",
    "                    if current_ngram_being_built_in_python.strip(): ngrams_for_this_keyword_list.append(current_ngram_being_built_in_python.strip())\n",
    "                    current_ngram_being_built_in_python = \"\"; keyword_ngram_generation_finished = True; break\n",
    "                current_ngram_being_built_in_python += lm[second_token_var]\n",
    "            for token_step in range(MAX_KEYWORD_LENGTH): # MAX_KEYWORD_LENGTH needs to be defined\n",
    "                continuations = find_next_word_continuations(current_ngram_being_built_in_python, trie_index_path_global) # trie_index_path_global\n",
    "                valid_next_strings = continuations + [')', ', ']\n",
    "                if ' ' not in continuations and (not current_ngram_being_built_in_python or current_ngram_being_built_in_python[-1] != ' '):\n",
    "                    valid_next_strings.append(' ')\n",
    "                valid_next_strings = list(set(s for s in valid_next_strings if s and s != '|'))\n",
    "                if not valid_next_strings: valid_next_strings = [')', ', ', ' ']\n",
    "                valid_next_strings = configure_list_size(valid_next_strings, 2000) # configure_list_size\n",
    "                if not valid_next_strings: valid_next_strings = [')']\n",
    "                current_token_var = f\"rephrase_{keyword_idx}_{rephrase_num}_token_{token_step}\"\n",
    "                lm += select(options=valid_next_strings, name=current_token_var)\n",
    "                selected_token_str = lm[current_token_var]\n",
    "                if selected_token_str == ')':\n",
    "                    if current_ngram_being_built_in_python.strip(): ngrams_for_this_keyword_list.append(current_ngram_being_built_in_python.strip())\n",
    "                    current_ngram_being_built_in_python = \"\"; keyword_ngram_generation_finished = True; break\n",
    "                elif selected_token_str == ', ':\n",
    "                    if current_ngram_being_built_in_python.strip(): ngrams_for_this_keyword_list.append(current_ngram_being_built_in_python.strip())\n",
    "                    current_ngram_being_built_in_python = \"\"\n",
    "                    if rephrase_num < MAX_REPHRASES - 1: lm += \" \"\n",
    "                    break \n",
    "                else: current_ngram_being_built_in_python += selected_token_str\n",
    "            if keyword_ngram_generation_finished: break\n",
    "        if current_ngram_being_built_in_python.strip(): ngrams_for_this_keyword_list.append(current_ngram_being_built_in_python.strip())\n",
    "        if ngrams_for_this_keyword_list: all_parsed_ngrams_for_bm25_queries.append(\" \".join(ngrams_for_this_keyword_list))\n",
    "\n",
    "\n",
    "    # 3. Retrieve with BM25 (Python logic)\n",
    "    retrieved_docs_by_bm25_nested: List[List[RetrievalResult]] = []\n",
    "    if all_parsed_ngrams_for_bm25_queries:\n",
    "        retrieved_docs_by_bm25_nested = bm25_index_global.retrieve( # bm25_index_global\n",
    "            nlqs=all_parsed_ngrams_for_bm25_queries,\n",
    "            output_folder=bm25_output_folder_global, # bm25_output_folder_global\n",
    "            k=BM25_K # BM25_K needs to be defined\n",
    "        )\n",
    "    \n",
    "    # 4. Collect unique objects (M candidates for MIP)\n",
    "    unique_retrieved_objects_map = {} # Maps BM25 doc_id to {'doc': RetrievalResult, 'max_bm25_score': float}\n",
    "    for result_list_for_query in retrieved_docs_by_bm25_nested:\n",
    "        for res_item in result_list_for_query:\n",
    "            # Assuming res_item.metadata['id'] is the unique ID from BM25\n",
    "            doc_id = res_item.metadata.get('id', res_item.object) # Fallback to object text if no id\n",
    "            if doc_id not in unique_retrieved_objects_map:\n",
    "                unique_retrieved_objects_map[doc_id] = {'doc': res_item, 'max_bm25_score': res_item.score}\n",
    "            else:\n",
    "                unique_retrieved_objects_map[doc_id]['max_bm25_score'] = max(\n",
    "                    unique_retrieved_objects_map[doc_id]['max_bm25_score'], res_item.score\n",
    "                )\n",
    "\n",
    "    if not unique_retrieved_objects_map:\n",
    "        lm += \"\\nNo relevant objects were initially retrieved by BM25.\"\n",
    "        # ... (rest of the no objects message) ...\n",
    "        lm += \"\\nHere are the objects that can be relevant to answer the user query:\\nNo relevant objects found.\\n\"\n",
    "        lm += \"\\nHere are the objects that are enough to answer the user query:\\nNo objects to select from.\\n<>\"\n",
    "        return lm\n",
    "\n",
    "    # 5. Prepare MIP Input - Calculate R_i using pre-computed FAISS embeddings (text-matching)\n",
    "    \n",
    "    # Encode query on-the-fly\n",
    "    query_embedding_np = embedding_model_global.encode(user_query, convert_to_numpy=True, show_progress_bar=False)\n",
    "    if query_embedding_np.ndim == 1: query_embedding_np = query_embedding_np.reshape(1, -1)\n",
    "    faiss.normalize_L2(query_embedding_np) \n",
    "    query_embedding_tensor = torch.tensor(query_embedding_np)\n",
    "\n",
    "    reconstructed_object_embeddings_list = []\n",
    "    # Store BM25 RetrievalResult objects for which we found FAISS embeddings, to maintain order for similarity scores\n",
    "    bm25_results_with_faiss_embeddings = [] \n",
    "\n",
    "    # Check if FAISS assets are loaded; if not, R_i will be 0 for all (or we could fall back to on-the-fly)\n",
    "    can_use_faiss_embeddings = (loaded_faiss_index is not None and \n",
    "                                loaded_faiss_text_to_original_idx_map is not None and\n",
    "                                len(loaded_faiss_text_to_original_idx_map) > 0)\n",
    "\n",
    "    if can_use_faiss_embeddings:\n",
    "        print(\"Attempting to use pre-computed FAISS embeddings (by text match)...\")\n",
    "        for bm25_doc_id_key, data_item in unique_retrieved_objects_map.items():\n",
    "            bm25_object_text = data_item['doc'].object \n",
    "            original_faiss_idx = loaded_faiss_text_to_original_idx_map.get(bm25_object_text)\n",
    "            \n",
    "            if original_faiss_idx is not None:\n",
    "                try:\n",
    "                    if 0 <= original_faiss_idx < loaded_faiss_index.ntotal:\n",
    "                        reconstructed_emb = loaded_faiss_index.reconstruct(original_faiss_idx)\n",
    "                        reconstructed_object_embeddings_list.append(reconstructed_emb)\n",
    "                        bm25_results_with_faiss_embeddings.append(data_item['doc']) # Store the BM25 doc\n",
    "                    # else: print(f\"Debug: FAISS index {original_faiss_idx} out of bounds for text: {bm25_object_text[:30]}\")\n",
    "                except Exception: # Catch-all for reconstruction errors\n",
    "                    # print(f\"Debug: Error reconstructing FAISS emb for text: {bm25_object_text[:30]}\")\n",
    "                    pass # Silently skip if reconstruction fails for an entry\n",
    "            # else:\n",
    "                # print(f\"Debug: Text not found in FAISS map: {bm25_object_text[:30]}\")\n",
    "\n",
    "\n",
    "    object_embeddings_tensor = torch.empty(0)\n",
    "    cosine_similarities_scores = [] # List of float scores\n",
    "\n",
    "    if reconstructed_object_embeddings_list:\n",
    "        object_embeddings_np_stack = np.array(reconstructed_object_embeddings_list)\n",
    "        if object_embeddings_np_stack.ndim == 1 and len(reconstructed_object_embeddings_list) == 1:\n",
    "             object_embeddings_np_stack = object_embeddings_np_stack.reshape(1, -1)\n",
    "        if object_embeddings_np_stack.size > 0:\n",
    "            object_embeddings_tensor = torch.tensor(object_embeddings_np_stack)\n",
    "\n",
    "    if query_embedding_tensor.nelement() > 0 and object_embeddings_tensor.nelement() > 0:\n",
    "        cosine_similarities_tensor = util.cos_sim(query_embedding_tensor, object_embeddings_tensor)[0]\n",
    "        cosine_similarities_scores = cosine_similarities_tensor.tolist()\n",
    "\n",
    "    # Map similarity scores back to the original BM25 unique objects\n",
    "    # This map uses the same key as unique_retrieved_objects_map (BM25 doc_id or fallback)\n",
    "    text_to_similarity_score_map = {}\n",
    "    for i, bm25_doc_found_in_faiss in enumerate(bm25_results_with_faiss_embeddings):\n",
    "        if i < len(cosine_similarities_scores):\n",
    "            # Use the object text of the BM25 doc that had a FAISS match as the key\n",
    "            text_key = bm25_doc_found_in_faiss.object \n",
    "            text_to_similarity_score_map[text_key] = (cosine_similarities_scores[i] + 1) / 2.0\n",
    "\n",
    "\n",
    "    mip_input_candidates = []\n",
    "    # Iterate through the original unique_retrieved_objects_map to build MIP candidates\n",
    "    for bm25_doc_id_key, data_item in unique_retrieved_objects_map.items():\n",
    "        doc_object_text = data_item['doc'].object\n",
    "        relevance_score_R_i = 0.0 # Default\n",
    "\n",
    "        if can_use_faiss_embeddings:\n",
    "            relevance_score_R_i = text_to_similarity_score_map.get(doc_object_text, 0.0)\n",
    "        else:\n",
    "            # Fallback: If FAISS pre-computed embeddings are not available/usable,\n",
    "            # calculate R_i on the fly for this specific object.\n",
    "            # This part makes it slower if FAISS fails, but keeps it functional.\n",
    "            # print(f\"FAISS pre-computed not used for: {doc_object_text[:30]}. Calculating on-the-fly.\")\n",
    "            obj_emb_tensor = embedding_model_global.encode(doc_object_text, convert_to_tensor=True, show_progress_bar=False)\n",
    "            if obj_emb_tensor.ndim == 1: obj_emb_tensor = obj_emb_tensor.unsqueeze(0) # Ensure 2D\n",
    "            if query_embedding_tensor.nelement() > 0 and obj_emb_tensor.nelement() > 0:\n",
    "                sim = util.cos_sim(query_embedding_tensor, obj_emb_tensor)[0][0].item()\n",
    "                relevance_score_R_i = (sim + 1) / 2.0\n",
    "        \n",
    "        source_str = data_item['doc'].metadata.get('source', 'unknown_source') \n",
    "        source_type = 'table' if source_str.startswith('table') else 'passage'\n",
    "        \n",
    "        parsed_content_val = None\n",
    "        if source_type == 'table':\n",
    "            parsed_content_val = parse_table_object_string(data_item['doc'].object) # parse_table_object_string\n",
    "        \n",
    "        mip_input_candidates.append({\n",
    "            'id': bm25_doc_id_key, # The unique ID from BM25 (or fallback)\n",
    "            'text': doc_object_text,\n",
    "            'source_type': source_type,\n",
    "            'parsed_content': parsed_content_val, \n",
    "            'relevance_score_R_i': relevance_score_R_i\n",
    "        })\n",
    "\n",
    "    # 6. MIP Solver (Python logic)\n",
    "    selected_objects_by_mip = []\n",
    "    if mip_input_candidates:\n",
    "        selected_objects_by_mip = solve_mip_object_selection( # solve_mip_object_selection\n",
    "            candidate_objects=mip_input_candidates,\n",
    "            k_select=K_MIP_SELECT, # K_MIP_SELECT needs to be defined\n",
    "            model=embedding_model_global # For compatibility calculations within MIP\n",
    "        )\n",
    "    \n",
    "    # 7. Construct LLM Prompt with MIP Results\n",
    "    lm += \"\\nHere are the objects that can be relevant to answer the user query:\\n\"\n",
    "    if selected_objects_by_mip:\n",
    "        for obj_data_item in selected_objects_by_mip:\n",
    "            lm += f\"- {obj_data_item['text']}\\n\"\n",
    "    else:\n",
    "        lm += \"No specific objects were selected by the solver as most relevant.\\n\"\n",
    "    \n",
    "    lm += \"\\nHere are the objects that are enough to answer the user query:\\n\"\n",
    "    lm += gen(name='final_selected_objects_and_reasoning', stop='<>') \n",
    "    lm += \"<>\"\n",
    "\n",
    "    return lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084708ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS assets not pre-initialized, attempting to initialize now (by text)...\n",
      "Initializing FAISS assets (by text) from: /data/hdd1/users/akouk/ARM/ARM/assets/feverous/faiss_indexes/dense_row_UAE-Large-V1\n",
      "FAISS assets (by text) initialized. Index has 391605 vectors.\n",
      "FAISS text-to-index map created with 389201 unique text entries from 391605 texts in metadata.pkl.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving with BM25: 100%|██████████| 6/6 [00:00<00:00, 5661.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to use pre-computed FAISS embeddings (by text match)...\n",
      "\n",
      "--- Final LLM Output ---\n",
      "You are given a user question, your task is to decompose the user question into contiguous, non-overlapping substrings that can\n",
      "cover different information mentioned in the user question. For each substring, generate n-grams that are the most relevant to\n",
      "the substring. Prefare lengthy n-grams over short ones. Based on the generated relevant n-grams, generate a list of relevant objects, including their names, content, and\n",
      "connections between these objects. From these candidate objects, you should identify the minimum number of objects that can\n",
      "be used to answer the user question based on the relevance between the object name, object content and user question as well as\n",
      "the relevance of the object connections. You should end your response with <>.\n",
      "\n",
      "User question: What is the birth date of the director of the movie 'Inception' which was released in 2010?\n",
      "The relevant keywords are birth date | director | movie 'Inception' | released in 2010\n",
      "The relevant n-grams are birth date (born, date of birth, DOB) | director (directed by, filmmaker, film director) | movie 'Inception' (Inception, film Inception, movie named Inception) | released in 2010 (2010, release year 2010, came out 2010)\n",
      "\n",
      "Here are the objects that can be relevant:\n",
      "(...4 objects omitted...)\n",
      "- Inception was directed by Christopher Nolan.\n",
      "- Lions live in the jungle.\n",
      "\n",
      "\n",
      "Here are the objects that are enough to answer the user query:\n",
      "(...2 objects omitted...)\n",
      "- Inception was directed by Christopher Nolan.\n",
      "\n",
      "\n",
      "User question: Aramais Yepiskoposan played for FC Ararat Yerevan, an Armenian football club based in Yerevan during 1986 to 1991.\n",
      "The relevant keywords are: Aramais Yepiskoposan | played for | FC Ararat Yerevan | Armenian football club | based in Yerevan | 1986 to 1991\n",
      "The relevant n-grams are Aramais Yepiskoposan (Aramais,  Yepiskoposyan) | played for (played for,  was a player,  was a member) | FC Ararat Yerevan (FC,  Ararat,  Yerevan) | Armenian football club (Armenian,  football club) | based in Yerevan (based in,  located in,  in) | 1986 to 1991 (1986,  1991,  1986 to 1991,  1986 - 1989,  1989 - 1990, \n",
      "Here are the objects that can be relevant to answer the user query:\n",
      "- FC Ararat Yerevan [SEP] Ararat Yerevan's reserve squad play as Ararat Yerevan-2 in the [[Armenian_First_League|Armenian First League]].\n",
      "- FC Ararat Yerevan [SEP] Football Club Ararat Yerevan ([[Armenian_language|Armenian]]: Ֆուտբոլային Ակումբ Արարատ Երևան), commonly known as Ararat Yerevan, is an Armenian [[Association_football|football]] club based in [[Yerevan|Yerevan]] that plays in the Armenian Premier League.\n",
      "- FC Ararat Yerevan [SEP] On 16 July 2018, Ararat Yerevan released a statement against the naming of [[FC_Ararat-Armenia|Ararat-Armenia]].\n",
      "- FC Ararat Yerevan [SEP] Ararat Yerevan run their own youth [[Dzoraghbyur_Training_Centre|training academy]] in the village of [[Dzoraghbyur|Dzoraghbyur]] at the eastern outskirts of the capital Yerevan.\n",
      "- FC Gandzasar Kapan [SEP] Football Club Gandzasar Kapan ([[Armenian_language|Armenian]]: Ֆուտբոլային Ակումբ Գանձասար Կապան), commonly known as Gandzasar, is an Armenian [[Association_football|football]] club based in the town of [[Kapan|Kapan]], [[Syunik_Province|Syunik Province]].\n",
      "\n",
      "Here are the objects that are enough to answer the user query:\n",
      "- FC Ararat Yerevan [SEP] Football Club Ararat Yerevan (Armenian: Ֆուտբոլային Ակումբ Արարատ Երևան), commonly known as Ararat Yerevan, is an Armenian football club based in Yerevan that plays in the Armenian Premier League.\n",
      "- Aramais Yepiskoposan [SEP] Aramais Yepiskoposan played for FC Ararat Yerevan from 1986 to 1991.\n",
      "\n",
      "<>\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "user_query = \"Aramais Yepiskoposan played for FC Ararat Yerevan, an Armenian football club based in Yerevan during 1986 to 1991.\"\n",
    "\n",
    "executed_program = model + dynamic_retrieval_guidance(user_query)\n",
    "\n",
    "# Print the final generated output\n",
    "print(\"\\n--- Final LLM Output ---\")\n",
    "print(str(executed_program))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tolis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
