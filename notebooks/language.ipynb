{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b2fdaf3",
   "metadata": {},
   "source": [
    "Chunk the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8423f580",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocess.sem_chunker import SemanticChunker\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "# --- Configuration ---\n",
    "INPUT_FILE_PATH = \"../assets/datagems/language_documents.json\"\n",
    "OUTPUT_FILE_PATH = \"../assets/datagems/language_documents_chunked.json\"\n",
    "CONTENT_FIELD = \"contents\"\n",
    "\n",
    "def chunk_json_file(input_path: str, output_path: str, content_field: str):\n",
    "    \"\"\"Reads, chunks, and writes JSON data.\"\"\"        \n",
    "    chunker = SemanticChunker() \n",
    "\n",
    "    with open(input_path, 'r', encoding='utf-8') as f_in:\n",
    "        data = json.load(f_in)\n",
    "\n",
    "    output_records = []\n",
    "    for record in tqdm(data, desc=\"Chunking records\", unit=\"record\", leave=False):\n",
    "        if isinstance(record, dict) and content_field in record:\n",
    "            text_to_chunk = record[content_field]\n",
    "            if isinstance(text_to_chunk, str) and text_to_chunk.strip():\n",
    "                chunks = chunker.pre_process(text_to_chunk)\n",
    "                for chunk_text in chunks:\n",
    "                    if chunk_text.strip(): # Ensure chunk itself isn't just whitespace\n",
    "                        new_record = record.copy()\n",
    "                        new_record[content_field] = chunk_text\n",
    "                        output_records.append(new_record)\n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    with open(output_path, 'w', encoding='utf-8') as f_out:\n",
    "        json.dump(output_records, f_out, indent=2, ensure_ascii=False)\n",
    "\n",
    "chunk_json_file(INPUT_FILE_PATH, OUTPUT_FILE_PATH, CONTENT_FIELD)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa224b0c",
   "metadata": {},
   "source": [
    "Convert to jsonl for compatibility with the retrievers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc29398f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[0;32m---> 13\u001b[0m         f\u001b[38;5;241m.\u001b[39mwrite(\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     15\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(json\u001b[38;5;241m.\u001b[39mdumps(data) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tolis/lib/python3.11/json/__init__.py:231\u001b[0m, in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# cached encoder\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m skipkeys \u001b[38;5;129;01mand\u001b[39;00m ensure_ascii \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     check_circular \u001b[38;5;129;01mand\u001b[39;00m allow_nan \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m separators \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     default \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sort_keys \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONEncoder\n",
      "File \u001b[0;32m~/miniconda3/envs/tolis/lib/python3.11/json/encoder.py:200\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m encode_basestring(o)\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_one_shot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    202\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(chunks)\n",
      "File \u001b[0;32m~/miniconda3/envs/tolis/lib/python3.11/json/encoder.py:258\u001b[0m, in \u001b[0;36mJSONEncoder.iterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    254\u001b[0m     _iterencode \u001b[38;5;241m=\u001b[39m _make_iterencode(\n\u001b[1;32m    255\u001b[0m         markers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault, _encoder, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindent, floatstr,\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort_keys,\n\u001b[1;32m    257\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskipkeys, _one_shot)\n\u001b[0;32m--> 258\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_iterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Paths\n",
    "input_path = \"../assets/datagems/language_documents.json\"\n",
    "output_path = \"../assets/datagems/language_documents.jsonl\"\n",
    "\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    if isinstance(data, list):\n",
    "        for item in data:\n",
    "            f.write(json.dumps(item) + \"\\n\")\n",
    "    else:\n",
    "        f.write(json.dumps(data) + \"\\n\")\n",
    "\n",
    "input_path = \"../assets/datagems/language_documents_semchunk.json\"\n",
    "output_path = \"../assets/datagems/language_documents_semchunk.jsonl\"\n",
    "\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    if isinstance(data, list):\n",
    "        for item in data:\n",
    "            f.write(json.dumps(item) + \"\\n\")\n",
    "    else:\n",
    "        f.write(json.dumps(data) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e06396",
   "metadata": {},
   "source": [
    "Defone the list of retrievers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41499ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BGE model: BAAI/bge-m3 (fp16: True) for Hybrid Search...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42cb45014fdd4a3e86dbe66e8d5c2cb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 30 files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BGE model loaded successfully.\n",
      "Initializing Qdrant client for HYBRID search: 195.251.63.238:6334 (gRPC: True)\n",
      "Qdrant client configured for collection 'datagems_language_hybrid_chunked'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/hdd1/users/akouk/ARM/ARM/src/retrieval/qdrant_hybrid.py:73: UserWarning: Failed to obtain server version. Unable to check client-server compatibility. Set check_version=False to skip version check.\n",
      "  self.client = QdrantClient(\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "#disable tqdm at all\n",
    "os.environ[\"DISABLE_TQDM\"] = \"1\"\n",
    "import tqdm  # or other modules that internally import tqdm\n",
    "\n",
    "from src.retrieval.base import BaseRetriever, RetrievalResult\n",
    "from src.retrieval.bm25 import PyseriniBM25Retriever\n",
    "from src.retrieval.dense import FaissDenseRetriever\n",
    "from src.retrieval.dense_rerank import DenseRetrieverWithReranker\n",
    "from src.retrieval.dense_decomp import DenseRetrieverWithDecomposition\n",
    "from src.retrieval.dense_decomp_rerank import DenseRetrieverWithDecompositionAndReranker\n",
    "from src.feverous.feverous_evaluator import FeverousEvaluation\n",
    "from src.retrieval.react import ReActRetriever\n",
    "from src.retrieval.qdrant_dense import QdrantBGEDenseRetriever\n",
    "from src.retrieval.qdrant_hybrid import QdrantBGEHybridRetriever\n",
    "from src.retrieval.qdrant_sparse_dense import QdrantBGEDenseSparseRetriever\n",
    "from typing import List\n",
    "MODEL_NAME = \"BAAI/bge-m3\"\n",
    "retriever_instances = {\n",
    "            #\"BM25\": lambda: PyseriniBM25Retriever(),\n",
    "            #\"Dense\": lambda: FaissDenseRetriever(model_name_or_path=MODEL_NAME),\n",
    "            #\"Dense+Rerank\": lambda: DenseRetrieverWithReranker(embedding_model_name=MODEL_NAME),\n",
    "            #\"Dense+Decomp\": lambda: DenseRetrieverWithDecomposition(decomposition_cache_folder=\"../assets/datagems/language_decomp\",embedding_model_name=MODEL_NAME,ollama_model=\"llama3.3:70b\"),\n",
    "            #\"Dense+Decomp+Rerank\": lambda: DenseRetrieverWithDecompositionAndReranker(decomposition_cache_folder=\"../assets/datagems/language_decomp\",embedding_model_name=MODEL_NAME),\n",
    "            #\"ReAct\": lambda: ReActRetriever(model_path=\"../assets/cache/Qwen2.5-32B-Instruct-Q4_K_M.gguf\",dense_model_name_or_path=MODEL_NAME)\n",
    "            #\"QdrantDenseOriginal\": lambda: QdrantBGEDenseRetriever(collection_name=\"datagems_language_original\"),\n",
    "            #\"QdrantDenseChunks\": lambda: QdrantBGEDenseRetriever(collection_name=\"datagems_language_chunked\"),\n",
    "            \"QdrantHybridOriginal\": lambda: QdrantBGEHybridRetriever(\n",
    "                collection_name=\"datagems_language_hybrid_chunked\", # Specific collection for hybrid original data\n",
    "            )\n",
    "            #\"QdrantHybridOriginal\": lambda: QdrantBGEHybridRetriever(\n",
    "            #    collection_name=\"datagems_language_hybrid_original\", # Specific collection for hybrid original data\n",
    "            #)\n",
    "        }\n",
    "retrievers: List[BaseRetriever] = []\n",
    "for name, init_func in retriever_instances.items():\n",
    "    retriever_instance = init_func()\n",
    "    retrievers.append(retriever_instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd28cc1",
   "metadata": {},
   "source": [
    "Perform the indexing with and without chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca52ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing chnked with QdrantBGEHybridRetriever\n",
      "Collection 'datagems_language_hybrid_chunked' found.\n",
      "Warning: Error checking collection 'datagems_language_hybrid_chunked' ('CollectionInfo' object has no attribute 'vectors_config'). Attempting to recreate...\n",
      "Collection 'datagems_language_hybrid_chunked' created/recreated successfully for hybrid search.\n",
      "Reading data from ../assets/datagems/language_documents_semchunk.jsonl...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b3e1c0aadc248378ecbb72169bfc08e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing JSONL: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating BGE-M3 hybrid embeddings for 3846805 documents...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ecec5fd6d34424f8d08b57d0c92fc44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding Batches:   0%|          | 0/470 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "initial target device: 100%|██████████| 2/2 [00:08<00:00,  4.17s/it]\n",
      "pre tokenize: 100%|██████████| 1/1 [00:00<00:00,  3.76it/s]\n",
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "pre tokenize: 100%|██████████| 1/1 [00:00<00:00,  3.57it/s]\n",
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "Inference Embeddings: 100%|██████████| 1/1 [00:06<00:00,  6.54s/it]\n",
      "Inference Embeddings: 100%|██████████| 1/1 [00:06<00:00,  6.74s/it]\n",
      "Chunks: 100%|██████████| 2/2 [00:19<00:00,  9.77s/it]\n",
      "pre tokenize: 100%|██████████| 1/1 [00:00<00:00,  3.10it/s]\n",
      "pre tokenize: 100%|██████████| 1/1 [00:00<00:00,  3.36it/s]\n",
      "Inference Embeddings: 100%|██████████| 1/1 [00:10<00:00, 10.45s/it]\n",
      "Inference Embeddings: 100%|██████████| 1/1 [00:10<00:00, 10.66s/it]\n",
      "Chunks: 100%|██████████| 2/2 [00:19<00:00,  9.72s/it]\n",
      "pre tokenize: 100%|██████████| 1/1 [00:00<00:00,  4.04it/s]\n",
      "pre tokenize: 100%|██████████| 1/1 [00:00<00:00,  3.60it/s]\n",
      "Inference Embeddings: 100%|██████████| 1/1 [00:10<00:00, 10.40s/it]\n",
      "Inference Embeddings: 100%|██████████| 1/1 [00:10<00:00, 10.67s/it]\n",
      "Chunks: 100%|██████████| 2/2 [00:18<00:00,  9.28s/it]\n",
      "pre tokenize: 100%|██████████| 1/1 [00:00<00:00,  3.76it/s]\n",
      "pre tokenize: 100%|██████████| 1/1 [00:00<00:00,  3.86it/s]\n",
      "Inference Embeddings: 100%|██████████| 1/1 [00:10<00:00, 10.47s/it]\n",
      "Inference Embeddings: 100%|██████████| 1/1 [00:10<00:00, 10.65s/it]\n",
      "Chunks: 100%|██████████| 2/2 [00:42<00:00, 21.14s/it]\n",
      "pre tokenize: 100%|██████████| 1/1 [00:00<00:00,  2.70it/s]\n",
      "pre tokenize: 100%|██████████| 1/1 [00:00<00:00,  2.14it/s]\n",
      "Inference Embeddings: 100%|██████████| 1/1 [00:10<00:00, 10.29s/it]\n",
      "Inference Embeddings: 100%|██████████| 1/1 [00:10<00:00, 10.48s/it]\n",
      "Chunks: 100%|██████████| 2/2 [00:16<00:00,  8.50s/it]\n",
      "pre tokenize: 100%|██████████| 1/1 [00:00<00:00,  4.38it/s]\n",
      "pre tokenize: 100%|██████████| 1/1 [00:00<00:00,  3.92it/s]\n",
      "Inference Embeddings: 100%|██████████| 1/1 [00:10<00:00, 10.94s/it]\n",
      "Inference Embeddings: 100%|██████████| 1/1 [00:11<00:00, 11.06s/it]\n",
      "Chunks: 100%|██████████| 2/2 [00:18<00:00,  9.24s/it]\n",
      "pre tokenize: 100%|██████████| 1/1 [00:00<00:00,  4.54it/s]\n",
      "pre tokenize: 100%|██████████| 1/1 [00:00<00:00,  4.11it/s]\n",
      "Inference Embeddings: 100%|██████████| 1/1 [00:11<00:00, 11.08s/it]\n",
      "Inference Embeddings: 100%|██████████| 1/1 [00:11<00:00, 11.02s/it]\n",
      "Chunks: 100%|██████████| 2/2 [00:19<00:00,  9.61s/it]\n",
      "pre tokenize: 100%|██████████| 1/1 [00:00<00:00,  4.64it/s]\n",
      "pre tokenize: 100%|██████████| 1/1 [00:00<00:00,  2.65it/s]\n",
      "Inference Embeddings: 100%|██████████| 1/1 [00:10<00:00, 10.98s/it]\n",
      "Inference Embeddings: 100%|██████████| 1/1 [00:11<00:00, 11.03s/it]\n",
      "Chunks: 100%|██████████| 2/2 [00:19<00:00,  9.95s/it]\n",
      "pre tokenize: 100%|██████████| 1/1 [00:00<00:00,  4.56it/s]\n",
      "pre tokenize: 100%|██████████| 1/1 [00:00<00:00,  4.47it/s]\n",
      "Inference Embeddings: 100%|██████████| 1/1 [00:10<00:00, 10.44s/it]\n",
      "Inference Embeddings: 100%|██████████| 1/1 [00:10<00:00, 10.70s/it]\n",
      "Chunks: 100%|██████████| 2/2 [00:19<00:00,  9.62s/it]\n",
      "pre tokenize: 100%|██████████| 1/1 [00:00<00:00,  5.05it/s]\n",
      "pre tokenize: 100%|██████████| 1/1 [00:00<00:00,  2.68it/s]\n",
      "Inference Embeddings: 100%|██████████| 1/1 [00:10<00:00, 10.58s/it]\n",
      "Inference Embeddings: 100%|██████████| 1/1 [00:10<00:00, 10.76s/it]\n",
      "Chunks: 100%|██████████| 2/2 [00:17<00:00,  8.93s/it]\n",
      "pre tokenize: 100%|██████████| 1/1 [00:00<00:00,  4.59it/s]\n",
      "pre tokenize: 100%|██████████| 1/1 [00:00<00:00,  4.15it/s]\n",
      "Inference Embeddings: 100%|██████████| 1/1 [00:10<00:00, 10.96s/it]\n",
      "Inference Embeddings: 100%|██████████| 1/1 [00:11<00:00, 11.13s/it]\n",
      "Chunks: 100%|██████████| 2/2 [00:18<00:00,  9.33s/it]\n",
      "pre tokenize: 100%|██████████| 1/1 [00:00<00:00,  4.47it/s]\n",
      "pre tokenize: 100%|██████████| 1/1 [00:00<00:00,  4.32it/s]\n",
      "Inference Embeddings: 100%|██████████| 1/1 [00:10<00:00, 10.99s/it]\n",
      "Inference Embeddings: 100%|██████████| 1/1 [00:11<00:00, 11.15s/it]\n",
      "Chunks: 100%|██████████| 2/2 [00:18<00:00,  9.32s/it]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "INDEX_BASE_DIR = Path(\"../assets/datagems/indexes/language\")\n",
    "SERIALIZATION_FILENAMES = {\n",
    "    #\"original\": \"../assets/datagems/language_documents.jsonl\",\n",
    "    \"chnked\": \"../assets/datagems/language_documents_semchunk.jsonl\"\n",
    "}\n",
    "METADATA_FIELDS_TO_INDEX = [\"id\", \"source\",\"language\"]\n",
    "FIELD_TO_INDEX = \"contents\"\n",
    "\n",
    "def get_output_folder(base_dir: Path, retriever_instance: BaseRetriever,serialization_name:str) -> Path:\n",
    "    if isinstance(retriever_instance, (FaissDenseRetriever)):\n",
    "        return base_dir / f\"faiss_indexes_{MODEL_NAME}\" / f\"dense_{serialization_name}\"\n",
    "    elif isinstance(retriever_instance, PyseriniBM25Retriever):\n",
    "        return base_dir / \"pyserini_indexes\" / f\"bm25_{serialization_name}\"\n",
    "    else:\n",
    "        return \"\"\n",
    "    \n",
    "#iterate over serialization filenames\n",
    "for serialization_name, serialization_filename in SERIALIZATION_FILENAMES.items():\n",
    "    for retriever_instance in retrievers:\n",
    "        retriever_name = getattr(retriever_instance, '_retriever_name_id', retriever_instance.__class__.__name__)\n",
    "        is_qdrant = isinstance(retriever_instance, QdrantBGEDenseRetriever)\n",
    "        is_qdrant_original = is_qdrant and retriever_instance.collection_name == \"datagems_language_original\"\n",
    "        is_qdrant_chunks = is_qdrant and retriever_instance.collection_name == \"datagems_language_chunked\"\n",
    "        is_qdrant_hybrid_original = is_qdrant and retriever_instance.collection_name == \"datagems_language_hybrid_original\"\n",
    "        is_qdrant_hybrid_chunks = is_qdrant and retriever_instance.collection_name == \"datagems_language_hybrid_chunked\"\n",
    "        if serialization_name == \"original\" and (is_qdrant_chunks or is_qdrant_hybrid_chunks):\n",
    "            print(f\"-- Skipping: Indexing '{serialization_name}' data with Qdrant Chunks retriever ({retriever_name})\")\n",
    "            continue\n",
    "        if serialization_name == \"chnked\" and (is_qdrant_original or is_qdrant_hybrid_original):\n",
    "            print(f\"-- Skipping: Indexing '{serialization_name}' data with Qdrant Original retriever ({retriever_name})\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"Indexing {serialization_name} with {retriever_instance.__class__.__name__}\")\n",
    "        output_folder = get_output_folder(INDEX_BASE_DIR, retriever_instance,serialization_name)\n",
    "        retriever_instance.index(\n",
    "            input_jsonl_path=serialization_filename,\n",
    "            output_folder=output_folder,\n",
    "            metadata_fields=METADATA_FIELDS_TO_INDEX,\n",
    "            field_to_index=FIELD_TO_INDEX\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "758f8a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving for chnked with ReActRetriever\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c47a754b421146b8bdf37e5b035e507a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Queries (ReAct with Guidance):   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RetrievalResult(score=0.5995, object='de minéralogie et de géologie« (1841, 17. Aufl. 1886; deutsch, Stuttg. 1858)....', metadata={id: ger_de_271349, source: german_encyclopedia, language: de}), RetrievalResult(score=0.6661, object='Landshut, a city of the province of the Isar, situated  on that river, in the kingdom of Bavaria. It is in a picturesque situation,  overlooked by an ancient castle on an eminence. It contains about 600 houses,  and 8200 inhabitants. It is the seat of a university, in which are from 600 to  700 pupils, and which possesses a library of 100,000 volumes, and several  appropriate institutions for instruction in law, medicine, surgery, midwifery,...', metadata={id: eb_en_8524, source: britannica, language: en}), RetrievalResult(score=0.6029, object='Mohs, Friedrich, Mineralog, geb. 1774 zu Gernrode am Harz, studierte zu Halle, sodann auf der Bergakademie zu Freiberg und kam 1802 nach Wien, wo er die Beschreibung der Mineraliensammlung des Bankiers van der Null herausgab, Wien 1804, 2. Aufl. 1806. Nach mehren und größeren geologischen Reisen, zum Theil im Auftrage der Regierung, ward er 1811 zum Professor der Mineralogie am Johanneum zu Grätz ernannt. In gleicher Eigenschaft später in Freiberg und seit 1826 in...', metadata={id: ger_de_240308, source: german_encyclopedia, language: de}), RetrievalResult(score=0.6047, object='und wurde 1863 Professor der Physik, 1866 Professor der Mineralogie. Er schrieb: »Über die Monstrositäten tesseral kristallisierender Mineralien« (Freiberg 1858); »Tabellen zur Bestimmung der Mineralien mittels äußerer Kennzeichen« (Leipz. 1866; 7. Aufl. von Kolbeck, 1906); »Synopsis mineralogica« (Freiberg 1875; 4. Aufl. von Kolbeck, 1906); »Characteres mineralogici« (das. 1880, 2. Aufl. 1899)....', metadata={id: ger_de_407386, source: german_encyclopedia, language: de}), RetrievalResult(score=0.6136, object='Landshut (German: [ˈlantshuːt] ; Bavarian: Landshuad) is a town in Bavaria in the south-east of Germany. Situated on the banks of the River Isar, Landshut is the capital of Lower Bavaria, one of the seven administrative regions of the Free State of Bavaria. It is also the seat of the surrounding district and has a population of more than 75,000. Landshut is the largest city in Lower Bavaria, followed by Passau and Straubing, and Eastern Bavaria's second after Regensburg....', metadata={id: wiki_en_19030, source: wikipedia, language: en}), RetrievalResult(score=0.6045, object='Landshut , Bezirksstadt im bayr. Reg.-Bez. Niederbayern, an der Isar, (1900) 21.737 (1905: 24.137) E., Garnison, Land-, Amtsgericht, Handels- und Gewerbekammer, Gymnasium, Realschule, Ackerbau-, Obstbau-, Keramische Schule; 1800 – 26 Sitz einer Universität (jetzt in München); dabei Schloß Trausnitz (1204), einstige Residenz der Herzöge von Niederbayern und Ruine Wolfstein. – Vgl. Staudenraus (3...', metadata={id: ger_de_47996, source: german_encyclopedia, language: de}), RetrievalResult(score=0.6098, object='Landshut, Hauptstadt des Kreises Niederbayern, an der Isar, mit 10000 E., 5 Klöstern. Gymnasium, Martinskirche mit 422' hohem Thurm; Bergschloß Traußnitz, bedeutender Produktenhandel. Die 1800 von Ingolstadt hieher verlegte Universität kam 1827 nach München. Von 1353 bis 1506 war L. Residenz der Herzoge von Niederbayern. Treffen 21. April 1809....', metadata={id: ger_de_237501, source: german_encyclopedia, language: de}), RetrievalResult(score=0.5968, object='FUCHS, Johann Nepomuk von...', metadata={id: eb_en_26299, source: britannica, language: en}), RetrievalResult(score=0.6024, object='LANDSHUT , chief town of a government district in  Lower Bavaria, is situated on the right bank of the Isar, about 40 miles  north-east of Munich. As the seat of government for the district, it contains  all the appropriate administrative offices, and it is well supplied with  educational and charitable institutions, besides having a convent and several  nunneries. Of its numerous ecclesiastical buildings the most interesting are the  churches of St Martin (with a spire 463 feet high), St Iodocus, and the Holy...', metadata={id: eb_en_32987, source: britannica, language: en}), RetrievalResult(score=0.6182, object='occasion of the removal thither of the university of Landshut, in 1826 he was  appointed professor of mineralogy. In 1852 he retired from public life, and in  1854 he was raised to the nobility by the king of Bavaria. He died at Munich,  March 5, 1856. Mineralogy and inorganic chemistry are indebted to Fuchs for  numerous researches. He is more especially known for his discovery, in 1823, of  a process for making a soluble glass, used for fixing fresco-colours, according...', metadata={id: eb_en_26299, source: britannica, language: en})]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33ma-koukouvinis\u001b[0m (\u001b[33mlakhs\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/hdd1/users/akouk/ARM/ARM/notebooks/wandb/run-20250429_203127-jti4fajp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/darelab/datagems/runs/jti4fajp' target=\"_blank\">ReActRetriever</a></strong> to <a href='https://wandb.ai/darelab/datagems' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/darelab/datagems' target=\"_blank\">https://wandb.ai/darelab/datagems</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/darelab/datagems/runs/jti4fajp' target=\"_blank\">https://wandb.ai/darelab/datagems/runs/jti4fajp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-04-29 20:31:28,601 - root - ERROR - An error occurred during evaluation.\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/hdd1/users/akouk/ARM/ARM/src/datagems/language_evaluator.py\", line 164, in evaluate\n",
      "    gt_by_scenario, pred_by_scenario = self._load_and_prepare_data(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/data/hdd1/users/akouk/ARM/ARM/src/datagems/language_evaluator.py\", line 79, in _load_and_prepare_data\n",
      "    raise ValueError(\n",
      "ValueError: Mismatch between number of benchmark queries (1626) and number of retrieved result sets (1).\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ReActRetriever</strong> at: <a href='https://wandb.ai/darelab/datagems/runs/jti4fajp' target=\"_blank\">https://wandb.ai/darelab/datagems/runs/jti4fajp</a><br> View project at: <a href='https://wandb.ai/darelab/datagems' target=\"_blank\">https://wandb.ai/darelab/datagems</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250429_203127-jti4fajp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Mismatch between number of benchmark queries (1626) and number of retrieved result sets (1).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m wandb_group \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage_sample_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mserialization_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     36\u001b[0m wandb_name \u001b[38;5;241m=\u001b[39m retriever_instance\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m---> 37\u001b[0m \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mBENCHMARK_FILE_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretrieved_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_wandb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject_wandb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mWANDB_PROJECT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mentity_wandb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mWANDB_ENTITY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_wandb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwandb_group\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname_wandb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwandb_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     47\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/hdd1/users/akouk/ARM/ARM/src/datagems/language_evaluator.py:164\u001b[0m, in \u001b[0;36mLanguageEvaluator.evaluate\u001b[0;34m(self, benchmark_json_path, retrieved_results, total_seconds, enable_wandb, project_wandb, entity_wandb, group_wandb, name_wandb, verbose)\u001b[0m\n\u001b[1;32m    160\u001b[0m wandb_log_data \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# 1. Load and prepare data\u001b[39;00m\n\u001b[0;32m--> 164\u001b[0m     gt_by_scenario, pred_by_scenario \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_and_prepare_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbenchmark_json_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretrieved_results\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# 2. Calculate metrics for each scenario + Overall\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     all_scenarios_to_process \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscenario_names \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOverall\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/data/hdd1/users/akouk/ARM/ARM/src/datagems/language_evaluator.py:79\u001b[0m, in \u001b[0;36mLanguageEvaluator._load_and_prepare_data\u001b[0;34m(self, benchmark_json_path, retrieved_results)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(benchmark_data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(retrieved_results):\n\u001b[0;32m---> 79\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMismatch between number of benchmark queries (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(benchmark_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     81\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand number of retrieved result sets (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(retrieved_results)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     82\u001b[0m     )\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, benchmark_item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(benchmark_data):\n\u001b[1;32m     85\u001b[0m     query_lang \u001b[38;5;241m=\u001b[39m benchmark_item\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion_language\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Mismatch between number of benchmark queries (1626) and number of retrieved result sets (1)."
     ]
    }
   ],
   "source": [
    "from src.datagems.language_evaluator import LanguageEvaluator\n",
    "import json\n",
    "import time\n",
    "K = 50\n",
    "evaluator = LanguageEvaluator(n_values=[1, 5, 10,20])\n",
    "BENCHMARK_FILE_PATH = \"../assets/datagems/language_benchmark.json\"\n",
    "WANDB_PROJECT = \"datagems\"\n",
    "WANDB_ENTITY = \"darelab\"\n",
    "\n",
    "with open(BENCHMARK_FILE_PATH, 'r', encoding='utf-8') as f:\n",
    "    benchmark_data = json.load(f)\n",
    "all_nlqs = [record.get('question') for record in benchmark_data if record.get('question')]\n",
    "all_nlqs = all_nlqs[:1]  # Limit to the first 100 queries for testing\n",
    "for serialization_name, serialization_filename in SERIALIZATION_FILENAMES.items():\n",
    "    for retriever_instance in retrievers:\n",
    "        retriever_name = getattr(retriever_instance, '_retriever_name_id', retriever_instance.__class__.__name__)\n",
    "        is_qdrant = isinstance(retriever_instance, QdrantBGEDenseRetriever)\n",
    "        is_qdrant_original = is_qdrant and retriever_instance.collection_name == \"datagems_language_original\"\n",
    "        is_qdrant_chunks = is_qdrant and retriever_instance.collection_name == \"datagems_language_chunked\"\n",
    "        if serialization_name == \"original\" and is_qdrant_chunks:\n",
    "            print(f\"-- Skipping: Indexing '{serialization_name}' data with Qdrant Chunks retriever ({retriever_name})\")\n",
    "            continue\n",
    "        if serialization_name == \"chnked\" and is_qdrant_original:\n",
    "            print(f\"-- Skipping: Indexing '{serialization_name}' data with Qdrant Original retriever ({retriever_name})\")\n",
    "            continue\n",
    "        print(f\"Retrieving for {serialization_name} with {retriever_instance.__class__.__name__}\")\n",
    "        output_folder = get_output_folder(INDEX_BASE_DIR, retriever_instance,serialization_name)\n",
    "        start = time.time()\n",
    "        retrieved_results: List[List[RetrievalResult]] = retriever_instance.retrieve(\n",
    "            nlqs=all_nlqs,\n",
    "            output_folder=str(output_folder),\n",
    "            k=K)\n",
    "        print(retrieved_results[0])\n",
    "        end = time.time()\n",
    "        wandb_group = f\"language_sample_{serialization_name}\"\n",
    "        wandb_name = retriever_instance.__class__.__name__\n",
    "        evaluator.evaluate(\n",
    "            BENCHMARK_FILE_PATH,\n",
    "            retrieved_results,\n",
    "            end-start,\n",
    "            enable_wandb=True,\n",
    "            project_wandb=WANDB_PROJECT,\n",
    "            entity_wandb=WANDB_ENTITY,\n",
    "            group_wandb=wandb_group,\n",
    "            name_wandb=wandb_name,\n",
    "            verbose=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e3798b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving for chnked with ReActRetriever\n",
      "Failed to load FAISS index to GPU: Error in virtual void* faiss::gpu::StandardGpuResourcesImpl::allocMemory(const faiss::gpu::AllocRequest&) at /project/faiss/faiss/gpu/StandardGpuResources.cpp:577: Error: 'err == cudaSuccess' failed: StandardGpuResources: alloc fail type FlatData dev 0 space Device stream 0x55ba3def1770 size 15756513280 bytes (cudaMalloc error out of memory [2])\n",
      ". Using CPU index.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ad49fc0df744dbc970e6982457513d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Queries (ReAct with Guidance):   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b54ab4bf5674f7fba1c670062d6ac2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "StitchWidget(initial_height='auto', initial_width='100%', srcdoc='<!doctype html>\\n<html lang=\"en\">\\n<head>\\n …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.datagems.language_evaluator import LanguageEvaluator\n",
    "import json\n",
    "import time\n",
    "K = 50\n",
    "evaluator = LanguageEvaluator(n_values=[1, 5, 10,20])\n",
    "BENCHMARK_FILE_PATH = \"../assets/datagems/language_benchmark_sample.json\"\n",
    "WANDB_PROJECT = \"datagems\"\n",
    "WANDB_ENTITY = \"darelab\"\n",
    "\n",
    "\n",
    "with open(BENCHMARK_FILE_PATH, 'r', encoding='utf-8') as f:\n",
    "    benchmark_data = json.load(f)\n",
    "all_nlqs = [record.get('question') for record in benchmark_data if record.get('question')]\n",
    "for serialization_name, serialization_filename in SERIALIZATION_FILENAMES.items():\n",
    "    for retriever_instance in retrievers:\n",
    "        retriever_name = getattr(retriever_instance, '_retriever_name_id', retriever_instance.__class__.__name__)\n",
    "        is_qdrant = isinstance(retriever_instance, QdrantBGEDenseRetriever)\n",
    "        is_qdrant_original = is_qdrant and retriever_instance.collection_name == \"datagems_language_original\"\n",
    "        is_qdrant_chunks = is_qdrant and retriever_instance.collection_name == \"datagems_language_chunked\"\n",
    "        if serialization_name == \"original\" and is_qdrant_chunks:\n",
    "            print(f\"-- Skipping: Indexing '{serialization_name}' data with Qdrant Chunks retriever ({retriever_name})\")\n",
    "            continue\n",
    "        if serialization_name == \"chnked\" and is_qdrant_original:\n",
    "            print(f\"-- Skipping: Indexing '{serialization_name}' data with Qdrant Original retriever ({retriever_name})\")\n",
    "            continue\n",
    "        print(f\"Retrieving for {serialization_name} with {retriever_instance.__class__.__name__}\")\n",
    "        output_folder = get_output_folder(INDEX_BASE_DIR, retriever_instance,serialization_name)\n",
    "        start = time.time()\n",
    "        retrieved_results: List[List[RetrievalResult]] = retriever_instance.retrieve(\n",
    "            nlqs=all_nlqs,\n",
    "            output_folder=str(output_folder),\n",
    "            k=K)\n",
    "        end = time.time()\n",
    "        wandb_group = f\"language_sample_{serialization_name}\"\n",
    "        wandb_name = retriever_instance.__class__.__name__\n",
    "        evaluator.evaluate(\n",
    "            BENCHMARK_FILE_PATH,\n",
    "            retrieved_results,\n",
    "            end-start,\n",
    "            enable_wandb=True,\n",
    "            project_wandb=WANDB_PROJECT,\n",
    "            entity_wandb=WANDB_ENTITY,\n",
    "            group_wandb=wandb_group,\n",
    "            name_wandb=wandb_name,\n",
    "            verbose=False\n",
    "\n",
    "        )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edd02655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7780642b337b4d5a94cfc0e6449d5cc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 30 files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Qdrant client for 195.251.63.238:6334 (gRPC: True)\n",
      "Qdrant client configured.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/hdd1/users/akouk/ARM/ARM/src/retrieval/qdrant_dense.py:73: UserWarning: Failed to obtain server version. Unable to check client-server compatibility. Set check_version=False to skip version check.\n",
      "  self.client = QdrantClient(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from Faiss folder: ../assets/datagems/indexes/language/faiss_indexes_BAAI/bge-m3/dense_chnked\n",
      "Loading metadata...\n",
      "Loaded 3846805 metadata entries.\n",
      "Loading Faiss index...\n",
      "Loaded Faiss index with 3846805 vectors of dimension 1024.\n",
      "Collection 'datagems_language_chunked' not found. Creating...\n",
      "Collection 'datagems_language_chunked' created.\n",
      "Reconstructing vectors from Faiss index...\n",
      "Reconstructed 3846805 vectors.\n",
      "Upserting 3846805 points from Faiss to Qdrant collection 'datagems_language_chunked'...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "976391215ee84aa088d3a1b9ba081ea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserting Faiss data to Qdrant:   0%|          | 0/15027 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully indexed 3846805 points from Faiss folder '../assets/datagems/indexes/language/faiss_indexes_BAAI/bge-m3/dense_chnked' into Qdrant collection 'datagems_language_chunked'.\n"
     ]
    }
   ],
   "source": [
    "from src.retrieval.qdrant_dense import QdrantBGEDenseRetriever\n",
    "qdrant_instance = QdrantBGEDenseRetriever(collection_name=\"datagems_language_chunked\")\n",
    "qdrant_instance.index_from_faiss(\"../assets/datagems/indexes/language/faiss_indexes_BAAI/bge-m3/dense_chnked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1273a4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.retrieval.base import BaseRetriever, RetrievalResult\n",
    "\n",
    "BENCHMARK_FILE_PATH = \"../assets/datagems/language_benchmark.json\"\n",
    "import json\n",
    "from typing import List\n",
    "with open(BENCHMARK_FILE_PATH, 'r', encoding='utf-8') as f:\n",
    "    benchmark_data = json.load(f)\n",
    "all_nlqs = [record.get('question') for record in benchmark_data if record.get('question')]\n",
    "\n",
    "retrieved_results: List[List[RetrievalResult]] = qdrant_instance.retrieve(nlqs=all_nlqs,output_folder=\"\", k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e8e647",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_results[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tolis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
